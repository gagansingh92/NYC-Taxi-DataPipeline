# üöñ NYC Taxi Data Engineering Pipeline

## üìå Overview
End-to-end data engineering project for **NYC Yellow Taxi** trip records. It covers **ingestion ‚Üí profiling ‚Üí ETL ‚Üí semantic data modeling ‚Üí warehouse schema ‚Üí analytics-ready output**. The goal is a clean, reproducible pipeline that demonstrates **DAX-style KPI thinking in BI**, **semantic modeling**, and strong **ETL/data quality** practices.

**What you‚Äôll see**
- Trip & fare analytics, pickup/dropoff time intelligence, passenger trends
- Zone/bourough breakdowns with join to TLC **taxi_zones** metadata
- Profiling outputs (HTML/XLSX), warehouse DDL, and a clear **star schema**

---

## üìÅ Project Structure
NYC-Taxi-DataPipeline/
‚îú‚îÄ‚îÄ README.md                           # Project documentation
‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îî‚îÄ‚îÄ DataModel.png                   # Star schema / data model diagram
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ ETL_Final.ipynb                 # ETL pipeline (cleaning & transformations)
‚îÇ   ‚îî‚îÄ‚îÄ Taxi_Data_Profiling.ipynb       # Data profiling notebook
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îî‚îÄ‚îÄ ddl_dw_taxi.sql                 # Data warehouse DDL (fact + dimensions)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ taxi_zones.csv                  # TLC Taxi zones metadata
‚îî‚îÄ‚îÄ docs/
	‚îú‚îÄ‚îÄ data_dictionary_trip_records_yellow.pdf  # Data dictionary
	‚îú‚îÄ‚îÄ DataProfiling.html                        # Auto profiling report
	‚îú‚îÄ‚îÄ Data_Profiling.xlsx                       # Profiling summary
	‚îú‚îÄ‚îÄ Taxi_DataPipeline_doc_StepByStep.docx     # Deployment guide
	‚îî‚îÄ‚îÄ NYC_Taxi.pptx                             # Project presentation

---

## üõ†Ô∏è Technologies Used  
- **Python** (Pandas, NumPy, Jupyter)  
- **Data Profiling** ‚Äì ydata-profiling (Pandas Profiling)  
- **SQL** ‚Äì PostgreSQL / Amazon Redshift schema  
- **ETL Orchestration** ‚Äì Apache Airflow / AWS Glue  
- **Data Storage** ‚Äì S3 (cloud), CSV (local)  
- **Analytics & BI** ‚Äì Tableau / Power BI (DAX measures, semantic modeling)  

---

## üîç Key Modules  
- **Data Ingestion** ‚Üí Load raw trip records & taxi zone metadata.  
- **Data Profiling** ‚Üí Assess quality, missing values, distributions (`DataProfiling.html`).  
- **ETL Transformations** ‚Üí Cleaning, deriving metrics (trip distance bands, tip %, surcharges).  
- **Semantic Data Model** ‚Üí Star schema with fact & dimension tables (`images/DataModel.png`).  
- **Warehouse Integration** ‚Üí DDL in `sql/ddl_dw_taxi.sql` for Redshift/Postgres.  
- **Analytics Layer** ‚Üí KPIs like total fares, tips, tolls, congestion surcharge, YoY/MoM trends, and zone-level performance.  

---

## üìÑ Documentation  
- [Step-by-Step Pipeline Guide](./docs/Taxi_DataPipeline_doc_StepByStep.docx)  
- [NYC Taxi Data Dictionary](./docs/data_dictionary_trip_records_yellow.pdf)  
- [Data Profiling Report (HTML)](./docs/DataProfiling.html)  
- [Warehouse Schema DDL](./sql/ddl_dw_taxi.sql)  
- [Data Model Diagram](./images/DataModel.png)  

> ‚ö†Ô∏è Note: GitHub won‚Äôt render `.html` files directly. Download `DataProfiling.html` to view locally.  

---

## ‚ñ∂Ô∏è Getting Started  
1. Clone the repository:  
   ```bash
   git clone https://github.com/gagansingh92/NYC-Taxi-DataPipeline.git
   cd NYC-Taxi-DataPipeline

2.	Create a virtual environment & install dependencies:
	python -m venv .venv && source .venv/bin/activate
	pip install pandas numpy jupyter ydata-profiling

3.	Open Jupyter notebooks:
	jupyter notebook notebooks/

4.	(Optional) Create schema in Postgres/Redshift using:
	\i sql/ddl_dw_taxi.sql

---

## üôã Author

**Gagan Preet Singh**  
Email: gagan.link08@gmail.com  
[LinkedIn](https://www.linkedin.com/in/gagansingh87)
